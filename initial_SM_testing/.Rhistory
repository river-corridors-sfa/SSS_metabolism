#install.packages(devtools)
# If you have trouble installing rstan, try the installation codes below:
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan", force = TRUE)
install.packages("rstan", type = "source")
# Run the line below if you have trouble installing devtools
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan")
install.packages("rstan")
knitr::opts_chunk$set(echo = TRUE)
#install.packages(remotes); library(remotes)
# remotes::install_github('appling/unitted', force = TRUE)
# remotes::install_github("USGS-R/streamMetabolizer", force = TRUE)
#install.packages("rstan", dependencies = FALSE)
#install.packages(devtools)
# If you have trouble installing rstan, try the installation codes below:
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan", force = TRUE)
#install.packages("rstan", type = "source")
# Run the line below if you have trouble installing devtools
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan")
rm(list=ls(all=T))
library(streamMetabolizer)
library(dplyr)
library(unitted)
library(ggplot2)
library(tidyr)
library(devtools)
library(rstan)
library(lubridate)
# Correctly installing rstan can be problematic, see GitHub for issues
osat<- function(temp, bp) {
tstd<-log((298.15-temp) / (273.15 + temp))
a0<-2.00907
a1<-3.22014
a2<-4.0501
a3<-4.94457
a4<- -0.256847
a5<- 3.88767
u<-10^(8.10765-(1750.286/(235+temp)))
sato<-(exp(a0 + a1*tstd + a2*tstd^2 + a3*tstd^3 + a4*tstd^4+a5*tstd^5))*((bp-u)/(760-u))*1.42905
sato
}
####function returns mm of Hg
bpcalc<- function(bpst, alt) {
bpst*25.4*exp((-9.80665*0.0289644*alt)/(8.31447*(273.15+15)))
}
#bp<-bpcalc(29.9, 489/3.28)# elevation at satus (alt in meters) #---------------------------------------------------------------------
data.path = "C:/Users/kauf093/OneDrive - PNNL/Spatial Study 2022/SSS_Data_Processing/4 - SSS_MiniDOT_with_Depth" #----------------
setwd(data.path)
dat = read.csv("SSS_MiniDOT_S31_with_Depth.csv",header=T) #---------------------------------------------------------------------------------------------
file.name = 'S31_test1'
#dat = na.omit(dat)
#dat=dat[450:33311-300,] #-------------------------------------------------------------------------------------------------------------
# Change date time format
head(dat)
colnames(dat)[1]
colnames(dat)[5]
osat<- function(temp, bp) {
tstd<-log((298.15-temp) / (273.15 + temp))
a0<-2.00907
a1<-3.22014
a2<-4.0501
a3<-4.94457
a4<- -0.256847
a5<- 3.88767
u<-10^(8.10765-(1750.286/(235+temp)))
sato<-(exp(a0 + a1*tstd + a2*tstd^2 + a3*tstd^3 + a4*tstd^4+a5*tstd^5))*((bp-u)/(760-u))*1.42905
sato
}
####function returns mm of Hg
bpcalc<- function(bpst, alt) {
bpst*25.4*exp((-9.80665*0.0289644*alt)/(8.31447*(273.15+15)))
}
#bp<-bpcalc(29.9, 489/3.28)# elevation at satus (alt in meters) #---------------------------------------------------------------------
data.path = "C:/Users/kauf093/OneDrive - PNNL/Spatial Study 2022/SSS_Data_Processing/4 - SSS_MiniDOT_with_Depth" #----------------
setwd(data.path)
dat = read.csv("SSS_MiniDOT_S31_with_Depth.csv",header=T) #---------------------------------------------------------------------------------------------
file.name = 'S31_test1'
#dat = na.omit(dat)
#dat=dat[450:33311-300,] #-------------------------------------------------------------------------------------------------------------
# Change date time format
colnames(dat)[5]="Unix.Timestamp"
dat$time<-as_datetime(dat$Unix.Timestamp)
#dat$DATE_TIME = as.POSIXct(dat$DATE_TIME, format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT+8")
# Transform date time into solar time
dat$solar.time<-convert_UTC_to_solartime(dat$time, longitude= -120.54798, time.type="mean solar") #----------------------------------
# Longitude is from your field site
head(dat)
dat$Lon[1]
osat<- function(temp, bp) {
tstd<-log((298.15-temp) / (273.15 + temp))
a0<-2.00907
a1<-3.22014
a2<-4.0501
a3<-4.94457
a4<- -0.256847
a5<- 3.88767
u<-10^(8.10765-(1750.286/(235+temp)))
sato<-(exp(a0 + a1*tstd + a2*tstd^2 + a3*tstd^3 + a4*tstd^4+a5*tstd^5))*((bp-u)/(760-u))*1.42905
sato
}
####function returns mm of Hg
bpcalc<- function(bpst, alt) {
bpst*25.4*exp((-9.80665*0.0289644*alt)/(8.31447*(273.15+15)))
}
#bp<-bpcalc(29.9, 489/3.28)# elevation at satus (alt in meters) #---------------------------------------------------------------------
data.path = "C:/Users/kauf093/OneDrive - PNNL/Spatial Study 2022/SSS_Data_Processing/4 - SSS_MiniDOT_with_Depth" #----------------
setwd(data.path)
dat = read.csv("SSS_MiniDOT_S31_with_Depth.csv",header=T) #---------------------------------------------------------------------------------------------
file.name = 'S31_test1'
#dat = na.omit(dat)
#dat=dat[450:33311-300,] #-------------------------------------------------------------------------------------------------------------
# Change date time format
colnames(dat)[5]="Unix.Timestamp"
dat$timeUTC<-as_datetime(dat$Unix.Timestamp)
#dat$DATE_TIME = as.POSIXct(dat$DATE_TIME, format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT+8")
# Transform date time into solar time
dat$solar.time<-convert_UTC_to_solartime(dat$timeUTC, longitude= dat$Lon[1], time.type="mean solar") #----------------------------------
# Longitude is from your field site
dat$Lat[1]
head(dat)
#bp<-bpcalc(29.9, 489/3.28)# elevation at satus (alt in meters) #---------------------------------------------------------------------
data.path = "C:/Users/kauf093/OneDrive - PNNL/Spatial Study 2022/SSS_Data_Processing/4 - SSS_MiniDOT_with_Depth" #----------------
setwd(data.path)
dat = read.csv("SSS_MiniDOT_S31_with_Depth.csv",header=T) #---------------------------------------------------------------------------------------------
file.name = 'S31_test1'
#dat = na.omit(dat)
#dat=dat[450:33311-300,] #-------------------------------------------------------------------------------------------------------------
# Change date time format
colnames(dat)[5]="Unix.Timestamp"
dat$timeUTC<-as_datetime(dat$Unix.Timestamp)
#dat$DATE_TIME = as.POSIXct(dat$DATE_TIME, format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT+8")
# Transform date time into solar time
dat$solar.time<-convert_UTC_to_solartime(dat$timeUTC, longitude= dat$Lon[1], time.type="mean solar") #----------------------------------
# Longitude is from your field site
# Calculate in mg/L for much DO you would have in the water at the current saturation conditions
#      dat$DOsat_mg_per_L =(dat$Dissolved.Oxygen*100)/dat$Dosat_pct #can put calibration offset factor in here
#dat$Dissolved.Oxygen<-dat$Dissolved.Oxygen*1.018951498 #-----------------------------------------------------------------------
# Reducing the number of decimals after performing the saturation calculations
#  dat$Dosat_mg_per_L = round(dat$DOsat_mg_per_L,2)
dat$light<- calc_light(dat$solar.time, latitude=dat$Lat[1], longitude=dat$Lon[1], max.PAR =2300, attach.units = F) #------------------
dat$DO.sat=osat(dat$TEMP_degreesC,dat$BP_mmhg)
dat$depth=DEPTH_m
head(dat)
#bp<-bpcalc(29.9, 489/3.28)# elevation at satus (alt in meters) #---------------------------------------------------------------------
data.path = "C:/Users/kauf093/OneDrive - PNNL/Spatial Study 2022/SSS_Data_Processing/4 - SSS_MiniDOT_with_Depth" #----------------
setwd(data.path)
dat = read.csv("SSS_MiniDOT_S31_with_Depth.csv",header=T) #---------------------------------------------------------------------------------------------
file.name = 'S31_test1'
#dat = na.omit(dat)
#dat=dat[450:33311-300,] #-------------------------------------------------------------------------------------------------------------
# Change date time format
colnames(dat)[5]="Unix.Timestamp"
dat$timeUTC<-as_datetime(dat$Unix.Timestamp)
#dat$DATE_TIME = as.POSIXct(dat$DATE_TIME, format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT+8")
# Transform date time into solar time
dat$solar.time<-convert_UTC_to_solartime(dat$timeUTC, longitude= dat$Lon[1], time.type="mean solar") #----------------------------------
# Longitude is from your field site
# Calculate in mg/L for much DO you would have in the water at the current saturation conditions
#      dat$DOsat_mg_per_L =(dat$Dissolved.Oxygen*100)/dat$Dosat_pct #can put calibration offset factor in here
#dat$Dissolved.Oxygen<-dat$Dissolved.Oxygen*1.018951498 #-----------------------------------------------------------------------
# Reducing the number of decimals after performing the saturation calculations
#  dat$Dosat_mg_per_L = round(dat$DOsat_mg_per_L,2)
dat$light<- calc_light(dat$solar.time, latitude=dat$Lat[1], longitude=dat$Lon[1], max.PAR =2300, attach.units = F) #------------------
dat$DO.sat=osat(dat$TEMP_degreesC,dat$BP_mmhg)
# Selecting the data types that are needed for stream metabolizer and changing header names. Running the model with K600_pooling = normal does not require discharge input
temp = dat
dat = cbind.data.frame(temp$solar.time,temp$DO_mg_per_L,temp$DO.sat,temp$TEMP_degreesC,temp$light,temp$DEPTH_m)
colnames(dat) = c("solar.time","DO.obs","DO.sat","temp.water","light","depth")
knitr::opts_chunk$set(echo = TRUE)
#install.packages(remotes); library(remotes)
# remotes::install_github('appling/unitted', force = TRUE)
# remotes::install_github("USGS-R/streamMetabolizer", force = TRUE)
#install.packages("rstan", dependencies = FALSE)
#install.packages(devtools)
# If you have trouble installing rstan, try the installation codes below:
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan", force = TRUE)
#install.packages("rstan", type = "source")
# Run the line below if you have trouble installing devtools
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan")
rm(list=ls(all=T))
library(streamMetabolizer)
library(dplyr)
library(unitted)
library(ggplot2)
library(tidyr)
library(devtools)
library(rstan)
library(lubridate)
# Correctly installing rstan can be problematic, see GitHub for issues
osat<- function(temp, bp) {
tstd<-log((298.15-temp) / (273.15 + temp))
a0<-2.00907
a1<-3.22014
a2<-4.0501
a3<-4.94457
a4<- -0.256847
a5<- 3.88767
u<-10^(8.10765-(1750.286/(235+temp)))
sato<-(exp(a0 + a1*tstd + a2*tstd^2 + a3*tstd^3 + a4*tstd^4+a5*tstd^5))*((bp-u)/(760-u))*1.42905
sato
}
####function returns mm of Hg
bpcalc<- function(bpst, alt) {
bpst*25.4*exp((-9.80665*0.0289644*alt)/(8.31447*(273.15+15)))
}
#bp<-bpcalc(29.9, 489/3.28)# elevation at satus (alt in meters) #---------------------------------------------------------------------
data.path = "C:/Users/kauf093/OneDrive - PNNL/Spatial Study 2022/SSS_Data_Processing/4 - SSS_MiniDOT_with_Depth" #----------------
setwd(data.path)
dat = read.csv("SSS_MiniDOT_S31_with_Depth.csv",header=T) #---------------------------------------------------------------------------------------------
file.name = 'S31_test1'
#dat = na.omit(dat)
#dat=dat[450:33311-300,] #-------------------------------------------------------------------------------------------------------------
# Change date time format
colnames(dat)[5]="Unix.Timestamp"
dat$timeUTC<-as_datetime(dat$Unix.Timestamp)
#dat$DATE_TIME = as.POSIXct(dat$DATE_TIME, format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT+8")
# Transform date time into solar time
dat$solar.time<-convert_UTC_to_solartime(dat$timeUTC, longitude= dat$Lon[1], time.type="mean solar") #----------------------------------
# Longitude is from your field site
# Calculate in mg/L for much DO you would have in the water at the current saturation conditions
#      dat$DOsat_mg_per_L =(dat$Dissolved.Oxygen*100)/dat$Dosat_pct #can put calibration offset factor in here
#dat$Dissolved.Oxygen<-dat$Dissolved.Oxygen*1.018951498 #-----------------------------------------------------------------------
# Reducing the number of decimals after performing the saturation calculations
#  dat$Dosat_mg_per_L = round(dat$DOsat_mg_per_L,2)
dat$light<- calc_light(dat$solar.time, latitude=dat$Lat[1], longitude=dat$Lon[1], max.PAR =2300, attach.units = F) #------------------
dat$DO.sat=osat(dat$TEMP_degreesC,dat$BP_mmhg)
# Selecting the data types that are needed for stream metabolizer and changing header names. Running the model with K600_pooling = normal does not require discharge input
temp = dat
dat = cbind.data.frame(temp$solar.time,temp$DO_mg_per_L,temp$DO.sat,temp$TEMP_degreesC,temp$light,temp$DEPTH_m)
colnames(dat) = c("solar.time","DO.obs","DO.sat","temp.water","light","depth")
parallel::detectCores()
dat %>% unitted::v() %>%
mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
select(solar.time, starts_with('DO')) %>%
gather(type, DO.value, starts_with('DO')) %>%
mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() +
facet_grid(units ~ ., scale='free_y') + theme_bw() +
scale_color_discrete('variable')
labels = c(temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
dat %>% unitted::v() %>%
select(solar.time, temp.water, light) %>%
gather(type, value, temp.water, light) %>%
mutate(
type=ordered(type, levels=c('temp.water','light')),
units=ordered(labels[type], unname(labels))) %>%
ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() +
facet_grid(units ~ ., scale='free_y') + theme_bw() +
scale_color_discrete('variable')
labels = c(temp.water='water temp\n(deg C)', depth='water depth')
dat %>% unitted::v() %>%
select(solar.time, temp.water, depth) %>%
gather(type, value, temp.water, depth) %>%
mutate(
type=ordered(type, levels=c('temp.water','depth')),
units=ordered(labels[type], unname(labels))) %>%
ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() +
facet_grid(units ~ ., scale='free_y') + theme_bw() +
scale_color_discrete('variable')
knitr::opts_chunk$set(echo = TRUE)
data<-read.csv("all_sites_Depth_Summary_with_width_and_velocity_for_K.csv")
data$Average_Depth_m=data$Average_Depth_cm/100
knitr::opts_chunk$set(echo = TRUE)
data<-read.csv("all_sites_Depth_Summary_with_width_and_velocity_for_K.csv")
data$Average_Depth_m=data$Average_Depth_cm/100
data$k600_md<-4725*(data$estimated_velocity_m_s*data$stream_slope_10m_frac)^0.86*data$estimated_discharge_cms^-0.14*data$Average_Depth_m^0.66
output<-data.frame(data[c("Site_ID","k600_md")])
write.csv(output,file='k600.csv')
log(24.9396659809312)
log10(24.9396659809312)
# Set the model
bayes_name = mm_name(type='bayes',
pool_K600='normal',
err_obs_iid=TRUE,
err_proc_iid=TRUE)
bayes_name
# Options for pool K600 are binned, linear, none and normal. If normal is specified, discharge doesn't need to be provided
# Changing the specs
bayes_specs = specs(bayes_name, K600_daily_meanlog_meanlog=log(24.9396659809312), K600_daily_meanlog_sdlog=0.7, K600_daily_sdlog_sigma=0.1, burnin_steps=1000,
saved_steps=1000)
mm = metab(bayes_specs, data=dat)#
knitr::opts_chunk$set(echo = TRUE)
#install.packages(remotes); library(remotes)
# remotes::install_github('appling/unitted', force = TRUE)
# remotes::install_github("USGS-R/streamMetabolizer", force = TRUE)
#install.packages("rstan", dependencies = FALSE)
#install.packages(devtools)
# If you have trouble installing rstan, try the installation codes below:
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan", force = TRUE)
#install.packages("rstan", type = "source")
# Run the line below if you have trouble installing devtools
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan")
rm(list=ls(all=T))
library(streamMetabolizer)
library(dplyr)
library(unitted)
library(ggplot2)
library(tidyr)
library(devtools)
library(rstan)
library(lubridate)
# Correctly installing rstan can be problematic, see GitHub for issues
osat<- function(temp, bp) {
tstd<-log((298.15-temp) / (273.15 + temp))
a0<-2.00907
a1<-3.22014
a2<-4.0501
a3<-4.94457
a4<- -0.256847
a5<- 3.88767
u<-10^(8.10765-(1750.286/(235+temp)))
sato<-(exp(a0 + a1*tstd + a2*tstd^2 + a3*tstd^3 + a4*tstd^4+a5*tstd^5))*((bp-u)/(760-u))*1.42905
sato
}
####function returns mm of Hg
bpcalc<- function(bpst, alt) {
bpst*25.4*exp((-9.80665*0.0289644*alt)/(8.31447*(273.15+15)))
}
#bp<-bpcalc(29.9, 489/3.28)# elevation at satus (alt in meters) #---------------------------------------------------------------------
data.path = "C:/Users/kauf093/OneDrive - PNNL/Spatial Study 2022/SSS_Data_Processing/4 - SSS_MiniDOT_with_Depth" #----------------
setwd(data.path)
dat = read.csv("SSS_MiniDOT_S31_with_Depth.csv",header=T) #---------------------------------------------------------------------------------------------
file.name = 'S31_test1'
#dat = na.omit(dat)
#dat=dat[450:33311-300,] #-------------------------------------------------------------------------------------------------------------
# Change date time format
colnames(dat)[5]="Unix.Timestamp"
dat$timeUTC<-as_datetime(dat$Unix.Timestamp)
#dat$DATE_TIME = as.POSIXct(dat$DATE_TIME, format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT+8")
# Transform date time into solar time
dat$solar.time<-convert_UTC_to_solartime(dat$timeUTC, longitude= dat$Lon[1], time.type="mean solar") #----------------------------------
# Longitude is from your field site
# Calculate in mg/L for much DO you would have in the water at the current saturation conditions
#      dat$DOsat_mg_per_L =(dat$Dissolved.Oxygen*100)/dat$Dosat_pct #can put calibration offset factor in here
#dat$Dissolved.Oxygen<-dat$Dissolved.Oxygen*1.018951498 #-----------------------------------------------------------------------
# Reducing the number of decimals after performing the saturation calculations
#  dat$Dosat_mg_per_L = round(dat$DOsat_mg_per_L,2)
dat$light<- calc_light(dat$solar.time, latitude=dat$Lat[1], longitude=dat$Lon[1], max.PAR =2300, attach.units = F) #------------------
dat$DO.sat=osat(dat$TEMP_degreesC,dat$BP_mmhg)
# Selecting the data types that are needed for stream metabolizer and changing header names. Running the model with K600_pooling = normal does not require discharge input
temp = dat
dat = cbind.data.frame(temp$solar.time,temp$DO_mg_per_L,temp$DO.sat,temp$TEMP_degreesC,temp$light,temp$DEPTH_m)
colnames(dat) = c("solar.time","DO.obs","DO.sat","temp.water","light","depth")
parallel::detectCores()
dat %>% unitted::v() %>%
mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
select(solar.time, starts_with('DO')) %>%
gather(type, DO.value, starts_with('DO')) %>%
mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() +
facet_grid(units ~ ., scale='free_y') + theme_bw() +
scale_color_discrete('variable')
labels = c(temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
dat %>% unitted::v() %>%
select(solar.time, temp.water, light) %>%
gather(type, value, temp.water, light) %>%
mutate(
type=ordered(type, levels=c('temp.water','light')),
units=ordered(labels[type], unname(labels))) %>%
ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() +
facet_grid(units ~ ., scale='free_y') + theme_bw() +
scale_color_discrete('variable')
labels = c(temp.water='water temp\n(deg C)', depth='water depth')
dat %>% unitted::v() %>%
select(solar.time, temp.water, depth) %>%
gather(type, value, temp.water, depth) %>%
mutate(
type=ordered(type, levels=c('temp.water','depth')),
units=ordered(labels[type], unname(labels))) %>%
ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() +
facet_grid(units ~ ., scale='free_y') + theme_bw() +
scale_color_discrete('variable')
# Set the model
bayes_name = mm_name(type='bayes',
pool_K600='normal',
err_obs_iid=TRUE,
err_proc_iid=TRUE)
bayes_name
# Options for pool K600 are binned, linear, none and normal. If normal is specified, discharge doesn't need to be provided
# Changing the specs
bayes_specs = specs(bayes_name, K600_daily_meanlog_meanlog=log(24.9396659809312), K600_daily_meanlog_sdlog=0.7, K600_daily_sdlog_sigma=0.1, burnin_steps=1000,
saved_steps=1000)
mm = metab(bayes_specs, data=dat)#
#Extracting the data from the model output the outputs are in a S4
#class of data and you'll need to operators to extract the daily
#time series of estimates
#get_fit(mm) %>%
#lapply(names)
# Saving key data
output.path = paste0(data.path,"/Output/")
preds = mm@fit$daily
#str(preds)
write.csv(preds,paste0(output.path,"Results_",file.name,Sys.Date(),".csv"))
data.path
#mm = metab(bayes_specs, data=dat)#
#Extracting the data from the model output the outputs are in a S4
#class of data and you'll need to operators to extract the daily
#time series of estimates
#get_fit(mm) %>%
#lapply(names)
# Saving key data
output.path = paste0(data.path,"/Output/")
preds = mm@fit$daily
#str(preds)
write.csv(preds,paste0(output.path,"Results_",file.name,Sys.Date(),".csv"))
instant = mm@fit$inst
#str(instant)
write.csv(instant,paste0(output.path,"Instant_",file.name,Sys.Date(),".csv"))
Overall = mm@fit$overall
#str(Overall)
write.csv(Overall,paste0(output.path,"Overall_",file.name,Sys.Date(),".csv"))
KQ = mm@fit$KQ_overall
#str(KQ)
write.csv(KQ,paste0(output.path,"KQ_ovearll",file.name,Sys.Date(),".csv"))
#get_data(mm)# Shows a table with all the data + DO modeled
#get_data_daily(mm) #daily fitting data. It shows values for Q for now
#get_params(mm)
predict_metab(mm)# Daily predictions of GPP and ER for the model
plot_metab_preds(mm)
get_params(mm)#to inspect more of the fitted daily parameters
predict_DO(mm) %>% head()
plot_DO_preds(mm)
get_fit(mm)$daily %>%
select(ends_with('Rhat'))#Daily Rhat for GPP, ER y K600
summary(preds$ER_Rhat)
summary(preds$GPP_Rhat)
summary(preds$K600_daily_Rhat)
get_fit(mm)$daily %>%
select(ends_with('n_eff'))#Daily n_eff for GPP, ER y K600
summary(preds$ER_n_eff)
summary(preds$GPP_n_eff)
summary(preds$K600_daily_n_eff)
#err_obs_iid_Rhat
get_fit(mm)$inst %>%
select(ends_with('Rhat'))
# err_obs_iid_sigma_Rhat. See comment from Appling
get_fit(mm)$overall %>%
select(ends_with('Rhat'))
get_fit(mm)$inst %>%
select(ends_with('n_eff'))
get_fit(mm)$overall %>%
select(ends_with('n_eff'))
summary(instant$err_obs_iid_n_eff)
summary(instant$err_obs_iid_Rhat)
summary(instant$err_proc_iid_n_eff)
summary(instant$err_proc_iid_Rhat)
summary(Overall$err_obs_iid_sigma_Rhat)# There is only one err_obs_iid_sigma_Rhat per run
summary(Overall$err_proc_iid_sigma_Rhat)
summary(Overall$err_obs_iid_sigma_n_eff)
summary(Overall$err_proc_iid_sigma_n_eff)
K600ER = lm(K600_daily_mean~ER_mean, data=preds)
plot(preds$ER_mean,preds$K600_daily_mean,xlab="ER_mean",ylab="Daily_mean_K600")
abline(lm(K600_daily_mean~ER_mean, data=preds))
legend("topright", bty="n", legend=paste("R2 =", format(summary(K600ER)$r.squared, digits=4)))
legend("top", bty="n", legend=paste("p = ", format(summary(K600ER)$coefficients[4], digits=4)))
summary(K600ER)
K600GPP = lm(K600_daily_mean~GPP_mean, data=preds)
plot(preds$GPP_mean,preds$K600_daily_mean,xlab="GPP_mean",ylab="Daily_mean_K600")
abline(lm(K600_daily_mean~GPP_mean, data=preds))
legend("topright", bty="n", legend=paste("R2 =", format(summary(K600GPP)$r.squared, digits=4)))
legend("top", bty="n", legend=paste("p = ", format(summary(K600GPP)$coefficients[4], digits=4)))
summary(K600GPP)
K600GPP = lm(K600_daily_mean~GPP_mean, data=preds)
plot(preds$GPP_mean,preds$K600_daily_mean,xlab="GPP_mean",ylab="Daily_mean_K600")
abline(lm(K600_daily_mean~GPP_mean, data=preds))
legend("topright", bty="n", legend=paste("R2 =", format(summary(K600GPP)$r.squared, digits=4)))
legend("top", bty="n", legend=paste("p = ", format(summary(K600GPP)$coefficients[4])))
summary(K600GPP)
preds$date = as.Date(preds$date)
plot(preds$date,preds$K600_daily_mean,
xlab="Date",ylab="Daily_mean_K600")
knit_with_parameters("~/GitHub/gitlab/SSS_metabolism/initial_SM_testing/smet_S31_test_A.Rmd")
knitr::opts_chunk$set
knitr::opts_chunk$set(eval = FALSE)
dat$solar.time = as.Date(dat$solar.time)
meanDday = aggregate(dat["DEPTH_m"],by = dat["solar.time"],mean)
head(dat)
dat$solar.time = as.Date(dat$solar.time)
meanDday = aggregate(dat["depth"],by = dat["solar.time"],mean)
K600D = lm(preds$K600_daily_mean~meanDday$depth)
length(preds$K600_daily_mean)
length(meanDday$depth)
head(preds)
head(meanDday)
tail(meanDday)
tail(preds
)
dat$solar.time = as.Date(dat$solar.time)
meanDday = aggregate(dat["depth"],by = dat["solar.time"],mean)
meanDday=meanDday[meanDday$solar.time %in% preds$date,]
K600D = lm(preds$K600_daily_mean~meanDday$depth)
plot(meanDday$depth,preds$K600_daily_mean,
xlab="D_daily_mean",ylab="Daily_mean_K600")
abline(lm(preds$K600_daily_mean~meanDday$depth))
legend("topright", bty="n", legend=paste("R2 =", format(summary(K600D)$r.squared, digits=4)))
legend("top", bty="n", legend=paste("p = ", format(summary(K600D)$coefficients[4], digits=4)))
summary(K600D)
dat$solar.time = as.Date(dat$solar.time)
meanDday = aggregate(dat["depth"],by = dat["solar.time"],mean)
meanDday=meanDday[meanDday$solar.time %in% preds$date,]
K600D = lm(preds$K600_daily_mean~meanDday$depth)
plot(meanDday$depth,preds$K600_daily_mean,
xlab="D_daily_mean",ylab="Daily_mean_K600")
abline(lm(preds$K600_daily_mean~meanDday$depth))
legend("topright", bty="n", legend=paste("R2 =", format(summary(K600D)$r.squared, digits=4)))
legend("top", bty="n", legend=paste("p = ", format(summary(K600D)$coefficients[8], digits=4)))
summary(K600D)
render("smet_S31_test_A.Rmd")
save(mm, "S31.RData") # saves the 'cars2' dataset
save.image("~/GitHub/gitlab/SSS_metabolism/initial_SM_testing/test.RData")
load("~/GitHub/gitlab/SSS_metabolism/initial_SM_testing/test.RData")
)
gc()
