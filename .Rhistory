View(data)
parent_ID <- str_extract(file, "[A-Z]{3}\\d{3}")
subset <- data %>%
filter(minute(DateTime) %% 15 == 0)
auto_clean <- auto_data_cleaning(
data = subset$Dissolved_Oxygen, # Dissolved Oxygen data
S = 96, # 96 intervals for daily seasonality (96 rows of 15 min data = 1 day of data)
tau = NULL, # Performs lasso to determine tau
no.of.last.indices.to.fix = nrow(tsrobprep_clean), # Fix all data points
indices.to.fix = NULL, # Automatically fix indices
detect.outliers.pars = list(method = c("IQR"),  # Use IQR for outlier detection
threshold = c(1.5)  # Common threshold for IQR
))
auto_clean <- auto_data_cleaning(
data = subset$Dissolved_Oxygen, # Dissolved Oxygen data
S = 96, # 96 intervals for daily seasonality (96 rows of 15 min data = 1 day of data)
tau = NULL, # Performs lasso to determine tau
no.of.last.indices.to.fix = nrow(subset), # Fix all data points
indices.to.fix = NULL, # Automatically fix indices
detect.outliers.pars = list(method = c("IQR"),  # Use IQR for outlier detection
threshold = c(1.5)  # Common threshold for IQR
))
clean_DO <- subset %>%
add_column(auto_clean$clean.data)
View(clean_DO)
clean_DO <- subset %>%
add_column(Cleaned_DO = auto_clean$clean.data)
View(clean_DO)
view(auto_clean$clean.data)
View(auto_clean)
View(subset)
clean_DO <- subset %>%
add_column(Cleaned_DO = auto_clean$clean.data$V1)
clean_DO <- subset %>%
add_column(Cleaned_DO = auto_clean$clean.data[1])
data <- read_csv(file, comment = '#', na = c('', '-9999',-9999, NA, 'N/A')) %>%
select(-Dissolved_Oxygen_Saturation)
subset <- data %>%
filter(minute(DateTime) %% 15 == 0)
clean_DO <- subset %>%
add_column(Cleaned_DO = auto_clean$clean.data[1])
max(clean_DO$Cleaned_DO) > 20
library(crayon)
cat(str_c(parent_ID, 'has data >20 mg/L. Removing cleaned DO and using original DO.'), "\n")
cat(red$bold(str_c(parent_ID, 'has data >20 mg/L. Removing cleaned DO and using original DO.')), "\n")
cat(red$bold(str_c(parent_ID, ' has data >20 mg/L. Removing cleaned DO and using original DO.')), "\n")
View(clean_DO)
if(max(clean_DO$Cleaned_DO) > 20){
clean_DO <- clean_DO %>%
select(-Cleaned_DO)
cat(red$bold(str_c(parent_ID, ' has data >20 mg/L. Removing cleaned DO and using original DO.')), "\n")
} else {
clean_DO <- clean_DO %>%
select(-Dissolved_Oxygen) %>%
rename(Dissolved_Oxygen = clean_DO)
}
clean_DO <- clean_DO %>%
select(-Dissolved_Oxygen) %>%
rename(Dissolved_Oxygen = Cleaned_DO)
if(max(clean_DO$Cleaned_DO) > 20){
clean_DO <- clean_DO %>%
select(-Cleaned_DO)
cat(red$bold(str_c(parent_ID, ' has data >20 mg/L. Removing cleaned DO and using original DO.')), "\n")
} else {
clean_DO <- clean_DO %>%
select(-Dissolved_Oxygen) %>%
rename(Dissolved_Oxygen = Cleaned_DO)
}
clean_DO <- subset %>%
add_column(Cleaned_DO = auto_clean$clean.data[1])
if(max(clean_DO$Cleaned_DO) > 20){
clean_DO <- clean_DO %>%
select(-Cleaned_DO)
cat(red$bold(str_c(parent_ID, ' has data >20 mg/L. Removing cleaned DO and using original DO.')), "\n")
} else {
clean_DO <- clean_DO %>%
select(-Dissolved_Oxygen) %>%
rename(Dissolved_Oxygen = Cleaned_DO)
}
View(clean_DO)
data <- read_csv(file, comment = '#', na = c('', '-9999',-9999, NA, 'N/A')) %>%
select(-Dissolved_Oxygen_Saturation, -Battery)
parent_ID <- str_extract(file, "[A-Z]{3}\\d{3}")
subset <- data %>%
filter(minute(DateTime) %% 15 == 0)
auto_clean <- auto_data_cleaning(
data = subset$Dissolved_Oxygen, # Dissolved Oxygen data
S = 96, # 96 intervals for daily seasonality (96 rows of 15 min data = 1 day of data)
tau = NULL, # Performs lasso to determine tau
no.of.last.indices.to.fix = nrow(subset), # Fix all data points
indices.to.fix = NULL, # Automatically fix indices
detect.outliers.pars = list(method = c("IQR"),  # Use IQR for outlier detection
threshold = c(1.5)  # Common threshold for IQR
))
clean_DO <- subset %>%
add_column(Cleaned_DO = auto_clean$clean.data[1])
if(max(clean_DO$Cleaned_DO) > 20){
clean_DO <- clean_DO %>%
select(-Cleaned_DO)
cat(red$bold(str_c(parent_ID, ' has data >20 mg/L. Removing cleaned DO and using original DO.')), "\n")
} else {
clean_DO <- clean_DO %>%
select(-Dissolved_Oxygen) %>%
rename(Dissolved_Oxygen = Cleaned_DO)
}
library(tidyverse)
library(crayon)
library(readxl)
library(glue)
rm(list=ls(all=T))
dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/'
dp_outdir <- 'Z:/00_Cross-SFA_ESSDIVE-Data-Package-Upload/01_Study-Data-Package-Folders/ECA_Data_Package/'
RC <- 'RC4'
study_code <- 'CM'
material <- 'Sediment'
hub_dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/Protocols-Guidance-Workflows-Methods/Methods_Codes/Hub-Typical-Codes-by-Study-Code.xlsx'
typical_codes_dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/Protocols-Guidance-Workflows-Methods/Methods_Codes/Method_Typical_Codes.xlsx'
material_fixed <- case_when(material == 'Sediment' ~ 'Sediment',
material == 'Water' ~ 'Liquid>aqueous')
combined_mapping <- list.files(paste0(dir, RC, '/FTICR/03_ProcessedData/', study_code, '_Data_Processed_FTICR'),'Mapping', full.names = T) %>%
read_csv()
list.files(paste0(dir, RC, '/FTICR/03_ProcessedData/', study_code, '_Data_Processed_FTICR'),'Mapping', full.names = T)
if('FALSE' %in% combined_mapping$Method_Status | NA %in% combined_mapping$Method_Status){
cat(
red$bold(
'Wait! Please check that \nMethods_Devation are completed.'
)
)
user <-
(readline(prompt = paste('Is it safe to continue? (Y/N)', sep = " ")
))
if(user == 'N'){
stop('Please finalize Methods Devations before proceeding.')
}
}
icr_boye_file <- combined_mapping %>%
select(Sample_ID, Method_Deviation)  %>%
filter(!str_detect(Sample_ID, 'Blk')) %>%
arrange(Sample_ID)%>%
mutate(Field_Name = case_when(row_number() == 1 ~ '#Start_Data',
TRUE ~ 'N/A'),
Methods_Deviation = case_when(is.na(Method_Deviation) ~ 'N/A',
TRUE ~ Method_Deviation)) %>%
add_column(Material = material_fixed,
'FTICR-MS' = 'See_FTICR_folder_for_data') %>%
rename(Sample_Name = Sample_ID) %>%
select(Field_Name, Sample_Name, Material, 'FTICR-MS', Methods_Deviation) %>%
add_row(Field_Name = '#End_Data',
Sample_Name = NA,
Material = NA,
'FTICR-MS' = NA,
Methods_Deviation = NA )
View(icr_boye_file)
View(combined_mapping)
combined_mapping <- list.files(paste0(dir, RC, '/FTICR/03_ProcessedData/', study_code, '_Data_Processed_FTICR'),'Mapping', full.names = T) %>%
read_csv() %>%
filter(str_detect(Sample_ID, 'SED'))
icr_boye_file <- combined_mapping %>%
select(Sample_ID, Method_Deviation)  %>%
filter(!str_detect(Sample_ID, 'Blk')) %>%
arrange(Sample_ID)%>%
mutate(Field_Name = case_when(row_number() == 1 ~ '#Start_Data',
TRUE ~ 'N/A'),
Methods_Deviation = case_when(is.na(Method_Deviation) ~ 'N/A',
TRUE ~ Method_Deviation)) %>%
add_column(Material = material_fixed,
'FTICR-MS' = 'See_FTICR_folder_for_data') %>%
rename(Sample_Name = Sample_ID) %>%
select(Field_Name, Sample_Name, Material, 'FTICR-MS', Methods_Deviation) %>%
add_row(Field_Name = '#End_Data',
Sample_Name = NA,
Material = NA,
'FTICR-MS' = NA,
Methods_Deviation = NA )
View(icr_boye_file)
# ========================= build header rows ==============================
hub <- read_excel(hub_dir)
boye_file_headers <- tibble(
'Field_Name' = c('Unit', 'Unit_Basis', 'MethodID_Analysis', 'MethodID_Inspection',
'MethodID_Storage', 'MethodID_Preservation', 'MethodID_Preparation',
'MethodID_DataProcessing', 'Analysis_DetectionLimit',
'Analysis_Precision', 'Data_Status'),
'Sample_Name' = c('N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',
'-9999', '-9999', 'N/A'),
'Material' = c('N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',
'-9999', '-9999', 'N/A')
)
analyte <- 'ICR'
filter_hub <- hub %>%
filter(RC == RC,
Study_Code == study_code,
Data_Package_Unit == material)
typical_code_number <-  filter_hub %>%
select(contains(analyte)) %>%
pull(1)
typical_codes <- read_excel(typical_codes_dir, sheet = paste0(analyte,"_Typical"))
order <- c('MethodID_Analysis', 'MethodID_Inspection',
'MethodID_Storage', 'MethodID_Preservation',
'MethodID_Preparation', 'MethodID_DataProcessing')
column_typical_codes <- typical_codes %>%
filter(str_detect(Method_ID, typical_code_number)) %>%
slice(match(order, Method_Type))%>%
select(Method_ID)%>%
pull(n = 1)
unit <- 'N/A'
unit_basis <- 'N/A'
data_status <- 'raw'
boye_file_headers <- boye_file_headers %>%
add_column('FTICR-MS'= c(unit, unit_basis, column_typical_codes, '-9999', '-9999', data_status),
'Methods_Deviation' = 'N/A')
View(boye_file_headers)
View(combined_mapping)
rm(list=ls(all=T))
dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/'
dp_outdir <- 'Z:/00_Cross-SFA_ESSDIVE-Data-Package-Upload/01_Study-Data-Package-Folders/ECA_Data_Package/'
RC <- 'RC4'
study_code <- 'CM'
material <- 'Sediment'
hub_dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/Protocols-Guidance-Workflows-Methods/Methods_Codes/Hub-Typical-Codes-by-Study-Code.xlsx'
typical_codes_dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/Protocols-Guidance-Workflows-Methods/Methods_Codes/Method_Typical_Codes.xlsx'
material_fixed <- case_when(material == 'Sediment' ~ 'Sediment',
material == 'Water' ~ 'Liquid>aqueous')
analyte_code <- case_when(material == 'Sediment' ~ 'SED',
material == 'Water' ~ 'ICR')
combined_mapping <- list.files(paste0(dir, RC, '/FTICR/03_ProcessedData/', study_code, '_Data_Processed_FTICR'),'Mapping', full.names = T) %>%
read_csv() %>%
filter(str_detect(Sample_ID, analyte_code))
if('FALSE' %in% combined_mapping$Method_Status | NA %in% combined_mapping$Method_Status){
cat(
red$bold(
'Wait! Please check that \nMethods_Devation are completed.'
)
)
user <-
(readline(prompt = paste('Is it safe to continue? (Y/N)', sep = " ")
))
if(user == 'N'){
stop('Please finalize Methods Devations before proceeding.')
}
}
icr_boye_file <- combined_mapping %>%
select(Sample_ID, Method_Deviation)  %>%
filter(!str_detect(Sample_ID, 'Blk')) %>%
arrange(Sample_ID)%>%
mutate(Field_Name = case_when(row_number() == 1 ~ '#Start_Data',
TRUE ~ 'N/A'),
Methods_Deviation = case_when(is.na(Method_Deviation) ~ 'N/A',
TRUE ~ Method_Deviation)) %>%
add_column(Material = material_fixed,
'FTICR-MS' = 'See_FTICR_folder_for_data') %>%
rename(Sample_Name = Sample_ID) %>%
select(Field_Name, Sample_Name, Material, 'FTICR-MS', Methods_Deviation) %>%
add_row(Field_Name = '#End_Data',
Sample_Name = NA,
Material = NA,
'FTICR-MS' = NA,
Methods_Deviation = NA )
# ========================= build header rows ==============================
hub <- read_excel(hub_dir)
boye_file_headers <- tibble(
'Field_Name' = c('Unit', 'Unit_Basis', 'MethodID_Analysis', 'MethodID_Inspection',
'MethodID_Storage', 'MethodID_Preservation', 'MethodID_Preparation',
'MethodID_DataProcessing', 'Analysis_DetectionLimit',
'Analysis_Precision', 'Data_Status'),
'Sample_Name' = c('N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',
'-9999', '-9999', 'N/A'),
'Material' = c('N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',
'-9999', '-9999', 'N/A')
)
analyte <- 'ICR'
filter_hub <- hub %>%
filter(RC == RC,
Study_Code == study_code,
Data_Package_Unit == material)
typical_code_number <-  filter_hub %>%
select(contains(analyte)) %>%
pull(1)
typical_codes <- read_excel(typical_codes_dir, sheet = paste0(analyte,"_Typical"))
order <- c('MethodID_Analysis', 'MethodID_Inspection',
'MethodID_Storage', 'MethodID_Preservation',
'MethodID_Preparation', 'MethodID_DataProcessing')
column_typical_codes <- typical_codes %>%
filter(str_detect(Method_ID, typical_code_number)) %>%
slice(match(order, Method_Type))%>%
select(Method_ID)%>%
pull(n = 1)
unit <- 'N/A'
unit_basis <- 'N/A'
data_status <- 'raw'
boye_file_headers <- boye_file_headers %>%
add_column('FTICR-MS'= c(unit, unit_basis, column_typical_codes, '-9999', '-9999', data_status),
'Methods_Deviation' = 'N/A')
unit
unit_basis
column_typical_codes
Method_ID
typical_code_number
typical_codes %>%
filter(str_detect(Method_ID, typical_code_number))
View(typical_codes)
rm(list=ls(all=T))
dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/'
dp_outdir <- 'Z:/00_Cross-SFA_ESSDIVE-Data-Package-Upload/01_Study-Data-Package-Folders/ECA_Data_Package/'
RC <- 'RC4'
study_code <- 'CM'
material <- 'Sediment'
hub_dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/Protocols-Guidance-Workflows-Methods/Methods_Codes/Hub-Typical-Codes-by-Study-Code.xlsx'
typical_codes_dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/Protocols-Guidance-Workflows-Methods/Methods_Codes/Method_Typical_Codes.xlsx'
material_fixed <- case_when(material == 'Sediment' ~ 'Sediment',
material == 'Water' ~ 'Liquid>aqueous')
analyte_code <- case_when(material == 'Sediment' ~ 'SED',
material == 'Water' ~ 'ICR')
combined_mapping <- list.files(paste0(dir, RC, '/FTICR/03_ProcessedData/', study_code, '_Data_Processed_FTICR'),'Mapping', full.names = T) %>%
read_csv() %>%
filter(str_detect(Sample_ID, analyte_code))
if('FALSE' %in% combined_mapping$Method_Status | NA %in% combined_mapping$Method_Status){
cat(
red$bold(
'Wait! Please check that \nMethods_Devation are completed.'
)
)
user <-
(readline(prompt = paste('Is it safe to continue? (Y/N)', sep = " ")
))
if(user == 'N'){
stop('Please finalize Methods Devations before proceeding.')
}
}
icr_boye_file <- combined_mapping %>%
select(Sample_ID, Method_Deviation)  %>%
filter(!str_detect(Sample_ID, 'Blk')) %>%
arrange(Sample_ID)%>%
mutate(Field_Name = case_when(row_number() == 1 ~ '#Start_Data',
TRUE ~ 'N/A'),
Methods_Deviation = case_when(is.na(Method_Deviation) ~ 'N/A',
TRUE ~ Method_Deviation)) %>%
add_column(Material = material_fixed,
'FTICR-MS' = 'See_FTICR_folder_for_data') %>%
rename(Sample_Name = Sample_ID) %>%
select(Field_Name, Sample_Name, Material, 'FTICR-MS', Methods_Deviation) %>%
add_row(Field_Name = '#End_Data',
Sample_Name = NA,
Material = NA,
'FTICR-MS' = NA,
Methods_Deviation = NA )
# ========================= build header rows ==============================
hub <- read_excel(hub_dir)
boye_file_headers <- tibble(
'Field_Name' = c('Unit', 'Unit_Basis', 'MethodID_Analysis', 'MethodID_Inspection',
'MethodID_Storage', 'MethodID_Preservation', 'MethodID_Preparation',
'MethodID_DataProcessing', 'Analysis_DetectionLimit',
'Analysis_Precision', 'Data_Status'),
'Sample_Name' = c('N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',
'-9999', '-9999', 'N/A'),
'Material' = c('N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',
'-9999', '-9999', 'N/A')
)
analyte <- 'ICR'
filter_hub <- hub %>%
filter(RC == RC,
Study_Code == study_code,
Data_Package_Unit == material)
typical_code_number <-  filter_hub %>%
select(contains(analyte)) %>%
pull(1)
typical_codes <- read_excel(typical_codes_dir, sheet = paste0(analyte,"_Typical"))
order <- c('MethodID_Analysis', 'MethodID_Inspection',
'MethodID_Storage', 'MethodID_Preservation',
'MethodID_Preparation', 'MethodID_DataProcessing')
column_typical_codes <- typical_codes %>%
filter(str_detect(Method_ID, typical_code_number)) %>%
slice(match(order, Method_Type))%>%
select(Method_ID)%>%
pull(n = 1)
unit <- 'N/A'
unit_basis <- 'N/A'
data_status <- 'raw'
boye_file_headers <- boye_file_headers %>%
add_column('FTICR-MS'= c(unit, unit_basis, column_typical_codes, '-9999', '-9999', data_status),
'Methods_Deviation' = 'N/A')
columns <- length(icr_boye_file) - 1
header_rows <- length(boye_file_headers$Field_Name) + 1
top <- tibble('one' = as.character(),
'two' = as.numeric()) %>%
add_row(one = '#Columns',
two = columns) %>%
add_row(one = '#Header_Rows',
two = header_rows)
out_name <- glue('{dp_outdir}{study_code}_{material}_FTICR_Methods_{Sys.Date()}.csv' )
out_name
dp_outdir <- 'Z:/00_Cross-SFA_ESSDIVE-Data-Package-Upload/01_Study-Data-Package-Folders/CM_SSS_Data_Package_v5/v5_CM_SSS_Data_Package/Sample_Data/'
out_name <- glue('{dp_outdir}{study_code}_{material}_FTICR_Methods_{Sys.Date()}.csv' )
out_name
write_csv(top, out_name, col_names = F)
write_csv(boye_file_headers, out_name, append = T, col_names = T)
write_csv(icr_boye_file, out_name, append = T, na = '')
out_name
dp_outdir <- 'Z:/00_ESSDIVE/01_Study_DPs/CM_SSS_Data_Package_v5/v5_CM_SSS_Data_Package/Sample_Data/'
out_name <- glue('{dp_outdir}{study_code}_{material}_FTICR_Methods_{Sys.Date()}.csv' )
write_csv(top, out_name, col_names = F)
write_csv(boye_file_headers, out_name, append = T, col_names = T)
write_csv(icr_boye_file, out_name, append = T, na = '')
rm(list=ls(all=T))
dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/'
dp_outdir <- 'Z:/00_ESSDIVE/01_Study_DPs/CM_SSS_Data_Package_v5/v5_CM_SSS_Data_Package/Sample_Data/'
RC <- 'RC4'
study_code <- 'CM'
material <- 'Water'
hub_dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/Protocols-Guidance-Workflows-Methods/Methods_Codes/Hub-Typical-Codes-by-Study-Code.xlsx'
typical_codes_dir <- 'C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/Protocols-Guidance-Workflows-Methods/Methods_Codes/Method_Typical_Codes.xlsx'
material_fixed <- case_when(material == 'Sediment' ~ 'Sediment',
material == 'Water' ~ 'Liquid>aqueous')
analyte_code <- case_when(material == 'Sediment' ~ 'SED',
material == 'Water' ~ 'ICR')
combined_mapping <- list.files(paste0(dir, RC, '/FTICR/03_ProcessedData/', study_code, '_Data_Processed_FTICR'),'Mapping', full.names = T) %>%
read_csv() %>%
filter(str_detect(Sample_ID, analyte_code))
if('FALSE' %in% combined_mapping$Method_Status | NA %in% combined_mapping$Method_Status){
cat(
red$bold(
'Wait! Please check that \nMethods_Devation are completed.'
)
)
user <-
(readline(prompt = paste('Is it safe to continue? (Y/N)', sep = " ")
))
if(user == 'N'){
stop('Please finalize Methods Devations before proceeding.')
}
}
View(combined_mapping)
icr_boye_file <- combined_mapping %>%
select(Sample_ID, Method_Deviation)  %>%
filter(!str_detect(Sample_ID, 'Blk')) %>%
arrange(Sample_ID)%>%
mutate(Field_Name = case_when(row_number() == 1 ~ '#Start_Data',
TRUE ~ 'N/A'),
Methods_Deviation = case_when(is.na(Method_Deviation) ~ 'N/A',
TRUE ~ Method_Deviation)) %>%
add_column(Material = material_fixed,
'FTICR-MS' = 'See_FTICR_folder_for_data') %>%
rename(Sample_Name = Sample_ID) %>%
select(Field_Name, Sample_Name, Material, 'FTICR-MS', Methods_Deviation) %>%
add_row(Field_Name = '#End_Data',
Sample_Name = NA,
Material = NA,
'FTICR-MS' = NA,
Methods_Deviation = NA )
# ========================= build header rows ==============================
hub <- read_excel(hub_dir)
boye_file_headers <- tibble(
'Field_Name' = c('Unit', 'Unit_Basis', 'MethodID_Analysis', 'MethodID_Inspection',
'MethodID_Storage', 'MethodID_Preservation', 'MethodID_Preparation',
'MethodID_DataProcessing', 'Analysis_DetectionLimit',
'Analysis_Precision', 'Data_Status'),
'Sample_Name' = c('N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',
'-9999', '-9999', 'N/A'),
'Material' = c('N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A',
'-9999', '-9999', 'N/A')
)
analyte <- 'ICR'
filter_hub <- hub %>%
filter(RC == RC,
Study_Code == study_code,
Data_Package_Unit == material)
typical_code_number <-  filter_hub %>%
select(contains(analyte)) %>%
pull(1)
typical_codes <- read_excel(typical_codes_dir, sheet = paste0(analyte,"_Typical"))
order <- c('MethodID_Analysis', 'MethodID_Inspection',
'MethodID_Storage', 'MethodID_Preservation',
'MethodID_Preparation', 'MethodID_DataProcessing')
column_typical_codes <- typical_codes %>%
filter(str_detect(Method_ID, typical_code_number)) %>%
slice(match(order, Method_Type))%>%
select(Method_ID)%>%
pull(n = 1)
unit <- 'N/A'
unit_basis <- 'N/A'
data_status <- 'raw'
boye_file_headers <- boye_file_headers %>%
add_column('FTICR-MS'= c(unit, unit_basis, column_typical_codes, '-9999', '-9999', data_status),
'Methods_Deviation' = 'N/A')
columns <- length(icr_boye_file) - 1
header_rows <- length(boye_file_headers$Field_Name) + 1
top <- tibble('one' = as.character(),
'two' = as.numeric()) %>%
add_row(one = '#Columns',
two = columns) %>%
add_row(one = '#Header_Rows',
two = header_rows)
out_name <- glue('{dp_outdir}{study_code}_{material}_FTICR_Methods_{Sys.Date()}.csv' )
write_csv(top, out_name, col_names = F)
write_csv(boye_file_headers, out_name, append = T, col_names = T)
write_csv(icr_boye_file, out_name, append = T, na = '')
weighted.mean(c(2.8868383344587, 2.970932708), c(14843, 12023))
weighted.mean(c(2.8868383344587, 2.970932708), c(14843, 12023))*100
14843+ 12023
current_path <- rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path)) # Sets working Directory to the current directory
library(tidyverse)
getwd
getwd()
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # Sets working Directory to the R project
setwd("C:/Brieanne/GitHub/SSS_metabolism/Stream_Metabolizer/Scripts")
data1<-read.csv("./../Inputs/v2_SSS_Water_Depth_Summary.csv", comment = '#') #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
setwd("C:/Brieanne/GitHub/SSS_metabolism")
data1<-read.csv("./v3_SSS_Data_Package/v3_SSS_Water_Depth_Summary.csv", comment = '#') #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
data1<-read_csv("./v3_SSS_Data_Package/v3_SSS_Water_Depth_Summary.csv", comment = '#') #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
setwd("C:/Brieanne/GitHub/SSS_metabolism")
data1<-read_csv("./v3_SSS_Data_Package/v3_SSS_Water_Depth_Summary.csv", comment = '#') #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
