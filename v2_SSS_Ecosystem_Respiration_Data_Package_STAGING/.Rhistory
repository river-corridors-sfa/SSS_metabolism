htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
#for(i in 1:length(SITE_LIST[,1])) {
for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
---
title: "stream metabolizer SSS template"
folder<-'Outputs/'
filenamelist<-list.files(folder, pattern='daily_prediction_results')
SITE_IDlist<-sapply(strsplit(filenamelist, "_"), "[", 2)
PARENT_IDlist<-sapply(strsplit(filenamelist, "_"), "[", 1)
depthfolder<-'Inputs/Sensor_Files/'
depthfilenamelist<-list.files(depthfolder, pattern='csv')
depthPARENT_IDlist<-sapply(strsplit(depthfilenamelist, "_"), "[", 1)
#create output dataframe
SMresults <- data.frame(matrix(ncol = 11, nrow = 0))
colnames(SMresults) <- c("Parent_ID","Site_ID", "daysofdata", "ERdailymeanmean_gO2/m2day", "GPPdailymeanmean_gO2/m2day", "K600dailymeanmean_m/day","mean_depth_m","ERdailymeanmean_gO2/m3day","GPPdailymeanmean_gO2/m3day","K600vsERrsq","K600vsERp")
#start loop
for(i in 1:length(PARENT_IDlist)) {
#for(i in 1) {
data = read.csv(paste(folder,filenamelist[i],sep=''),header=T)
numdays<-length(data$ER_daily_mean[!is.na(data$ER_daily_mean)])
ERdailymeanmean<-mean(data$ER_daily_mean[!is.na(data$ER_daily_mean)])
GPPdailymeanmean<-mean(data$GPP_daily_mean[!is.na(data$GPP_daily_mean)])
K600dailymeanmean<-mean(data$K600_daily_mean[!is.na(data$K600_daily_mean)])
depthfilenumber<-which(depthPARENT_IDlist == PARENT_IDlist[i])
depthdata<-read.csv(paste(depthfolder,depthfilenamelist[depthfilenumber],sep=''),header=T,skip=8)
meandepthm<-mean(depthdata$Depth,na.rm=TRUE)
ERdailymeanmeanm3<-ERdailymeanmean/meandepthm
GPPdailymeanmeanm3<-GPPdailymeanmean/meandepthm
lmK600ER = lm(ER_daily_mean~K600_daily_mean, data = data) #Create the linear regression
K600vsERp=summary(lmK600ER)$coefficients[2,4]
K600vsERrsq=summary(lmK600ER)$r.squared
SMresults[nrow(SMresults) + 1,] = c(PARENT_IDlist[i],SITE_IDlist[i], numdays,ERdailymeanmean,GPPdailymeanmean,K600dailymeanmean,meandepthm,ERdailymeanmeanm3,GPPdailymeanmeanm3,K600vsERrsq,K600vsERp)
}
folder<-'Outputs/'
filenamelist<-list.files(folder, pattern='daily_prediction_results')
SITE_IDlist<-sapply(strsplit(filenamelist, "_"), "[", 2)
PARENT_IDlist<-sapply(strsplit(filenamelist, "_"), "[", 1)
depthfolder<-'Inputs/Sensor_Files/'
depthfilenamelist<-list.files(depthfolder, pattern='csv')
depthPARENT_IDlist<-sapply(strsplit(depthfilenamelist, "_"), "[", 1)
#create output dataframe
SMresults <- data.frame(matrix(ncol = 11, nrow = 0))
colnames(SMresults) <- c("Parent_ID","Site_ID", "daysofdata", "ERdailymeanmean_gO2/m2day", "GPPdailymeanmean_gO2/m2day", "K600dailymeanmean_m/day","mean_depth_m","ERdailymeanmean_gO2/m3day","GPPdailymeanmean_gO2/m3day","K600vsERrsq","K600vsERp")
i = 1
#for(i in 1) {
data = read.csv(paste(folder,filenamelist[i],sep=''),header=T)
numdays<-length(data$ER_daily_mean[!is.na(data$ER_daily_mean)])
ERdailymeanmean<-mean(data$ER_daily_mean[!is.na(data$ER_daily_mean)])
GPPdailymeanmean<-mean(data$GPP_daily_mean[!is.na(data$GPP_daily_mean)])
K600dailymeanmean<-mean(data$K600_daily_mean[!is.na(data$K600_daily_mean)])
depthfilenumber<-which(depthPARENT_IDlist == PARENT_IDlist[i])
depthdata<-read.csv(paste(depthfolder,depthfilenamelist[depthfilenumber],sep=''),header=T,skip=8)
paste(depthfolder,depthfilenamelist[depthfilenumber],sep='')
which(depthPARENT_IDlist == PARENT_IDlist[i])
PARENT_IDlist[i]
PARENT_IDlist[i]
sapply(strsplit(depthfilenamelist, "v2_"), "[", 1)
sapply(strsplit(depthfilenamelist, "_v2"), "[", 1)
grep("^SSS\\d*", depthfilenamelist, value = TRUE)
depthfilenamelist
grep("^SSS\\d*", depthfilenamelist)
grep("^SSS.*", depthfilenamelist)
str_extract(depthfilenamelist,"^SSS.*")
str_extract(depthfilenamelist,"SSS.*")
str_extract(depthfilenamelist,"SSS(\\d+).*")
str_extract(depthfilenamelist,"SSS(\\d+)"
)
depthPARENT_IDlist<- str_extract(depthfilenamelist,"SSS(\\d+)")
#create output dataframe
SMresults <- data.frame(matrix(ncol = 11, nrow = 0))
colnames(SMresults) <- c("Parent_ID","Site_ID", "daysofdata", "ERdailymeanmean_gO2/m2day", "GPPdailymeanmean_gO2/m2day", "K600dailymeanmean_m/day","mean_depth_m","ERdailymeanmean_gO2/m3day","GPPdailymeanmean_gO2/m3day","K600vsERrsq","K600vsERp")
#for(i in 1) {
data = read.csv(paste(folder,filenamelist[i],sep=''),header=T)
numdays<-length(data$ER_daily_mean[!is.na(data$ER_daily_mean)])
ERdailymeanmean<-mean(data$ER_daily_mean[!is.na(data$ER_daily_mean)])
GPPdailymeanmean<-mean(data$GPP_daily_mean[!is.na(data$GPP_daily_mean)])
K600dailymeanmean<-mean(data$K600_daily_mean[!is.na(data$K600_daily_mean)])
depthfilenumber<-which(depthPARENT_IDlist == PARENT_IDlist[i])
depthdata<-read.csv(paste(depthfolder,depthfilenamelist[depthfilenumber],sep=''),header=T,skip=8)
getwd()
paste(depthfolder,depthfilenamelist[depthfilenumber],sep='')
paste(depthfolder,depthfilenamelist[depthfilenumber],sep='')
depthfilenamelist[depthfilenumber]
depthfilenumber
depthPARENT_IDlist
PARENT_IDlist[i]
SITE_IDlist
PARENT_IDlist
filenamelist
sapply(strsplit(filenamelist, "_"), "[", 3)
SITE_IDlist<-sapply(strsplit(filenamelist, "_"), "[", 3)
PARENT_IDlist<-sapply(strsplit(filenamelist, "_"), "[", 2)
sapply(strsplit(depthfilenamelist, "_"), "[", 2)
depthPARENT_IDlist<-  sapply(strsplit(depthfilenamelist, "_"), "[", 2)
folder<-'Outputs/'
filenamelist<-list.files(folder, pattern='daily_prediction_results')
SITE_IDlist<-sapply(strsplit(filenamelist, "_"), "[", 3)
PARENT_IDlist<-sapply(strsplit(filenamelist, "_"), "[", 2)
depthfolder<-'Inputs/Sensor_Files/'
depthfilenamelist<-list.files(depthfolder, pattern='csv')
depthPARENT_IDlist<-  sapply(strsplit(depthfilenamelist, "_"), "[", 2)
#create output dataframe
SMresults <- data.frame(matrix(ncol = 11, nrow = 0))
colnames(SMresults) <- c("Parent_ID","Site_ID", "daysofdata", "ERdailymeanmean_gO2/m2day", "GPPdailymeanmean_gO2/m2day", "K600dailymeanmean_m/day","mean_depth_m","ERdailymeanmean_gO2/m3day","GPPdailymeanmean_gO2/m3day","K600vsERrsq","K600vsERp")
#for(i in 1) {
data = read.csv(paste(folder,filenamelist[i],sep=''),header=T)
numdays<-length(data$ER_daily_mean[!is.na(data$ER_daily_mean)])
ERdailymeanmean<-mean(data$ER_daily_mean[!is.na(data$ER_daily_mean)])
GPPdailymeanmean<-mean(data$GPP_daily_mean[!is.na(data$GPP_daily_mean)])
K600dailymeanmean<-mean(data$K600_daily_mean[!is.na(data$K600_daily_mean)])
depthfilenumber<-which(depthPARENT_IDlist == PARENT_IDlist[i])
depthdata<-read.csv(paste(depthfolder,depthfilenamelist[depthfilenumber],sep=''),header=T,skip=8)
meandepthm<-mean(depthdata$Depth,na.rm=TRUE)
ERdailymeanmeanm3<-ERdailymeanmean/meandepthm
GPPdailymeanmeanm3<-GPPdailymeanmean/meandepthm
lmK600ER = lm(ER_daily_mean~K600_daily_mean, data = data) #Create the linear regression
K600vsERp=summary(lmK600ER)$coefficients[2,4]
K600vsERrsq=summary(lmK600ER)$r.squared
SMresults[nrow(SMresults) + 1,] = c(PARENT_IDlist[i],SITE_IDlist[i], numdays,ERdailymeanmean,GPPdailymeanmean,K600dailymeanmean,meandepthm,ERdailymeanmeanm3,GPPdailymeanmeanm3,K600vsERrsq,K600vsERp)
setwd("~/GitHub/SSS_metabolism/v2_SSS_Ecosystem_Respiration_Data_Package_STAGING/Scripts")
setwd("~/GitHub/SSS_metabolism/v2_SSS_Ecosystem_Respiration_Data_Package_STAGING")
getwd()
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
i
SITE_LIST[i,1]
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
#rm(list=ls(all=T))
library(fda)
library(streamMetabolizer)
library(dplyr)
library(unitted)
library(ggplot2)
library(tidyr)
library(devtools)
library(rstan)
library(lubridate)
# Correctly installing rstan can be problematic, see GitHub for issues
#-------------------------------------
#PARENT_ID='' #this is where you would specify a site if you were not running this as a loop
#-------------------------------------
print("PARENT_ID: ")
PARENT_ID<-'SSS001'
print("SITE_ID: ")
SITE_ID<-'S63'
data.path = "Inputs/"
dat = read.csv(paste0(data.path,'Sensor_Files/v2_',PARENT_ID,"_Temp_DO_Press_Depth.csv"),header=T,skip=8)
K600estimates=read.csv(paste0(data.path,'v2_SSS_K600.csv'),header=T,skip=3)
K600estimate<-K600estimates[K600estimates$Site_ID==SITE_ID,2]
print("K600 estimate: ")
K600estimate
output.path="Outputs/"
#---------------------------------------------------------------------------------------------
file.name = paste('v2_SSS_SM_',PARENT_ID,'_',SITE_ID,'_final',sep='')
#dat = na.omit(dat)
#dat=dat[450:33311-300,] #-------------------------------------------------------------------------------------------------------------
# Change date time format
#fix erroneous data by removing and replacing with fourrier-smoothed interpolation
dat$timeUTC<-as.POSIXct(dat$DateTime)+hours(8)
dat$timeUTC<-force_tz(dat$timeUTC,tzone='UTC')
tt<- as.integer(format(dat$timeUTC, "%s"))
DO<-dat$Dissolved_Oxygen
DObasis361 = create.fourier.basis(rangeval = range(tt),nbasis = 361)
DOfourier361.fd = smooth.basis(argvals = tt, y = DO,fdParobj = DObasis361)$fd
View(dat)
# Set the model
bayes_name = mm_name(type='bayes',
pool_K600='normal',
err_obs_iid=TRUE,
err_proc_iid=TRUE)
bayes_name
# Options for pool K600 are binned, linear, none and normal. If normal is specified, discharge doesn't need to be provided
# Changing the specs
bayes_specs = specs(bayes_name, K600_daily_meanlog_meanlog=log(K600estimate), K600_daily_meanlog_sdlog=0.7, K600_daily_sdlog_sigma=0.02, burnin_steps=1000,
saved_steps=1000)
mm = metab(bayes_specs, data=dat)#
dat$solar.time<-convert_UTC_to_solartime(dat$timeUTC, longitude= dat$Longitude[1], time.type="mean solar")
#DOWNSAMPLE
samplingmins=15
dat = dat[seq(1, nrow(dat), samplingmins), ]
dat$solar.time<-convert_UTC_to_solartime(dat$timeUTC, longitude= dat$Longitude[1], time.type="mean solar")
dat$light<- calc_light(dat$solar.time, latitude=dat$Latitude[1], longitude=dat$Longitude[1], max.PAR =2300, attach.units = F) #------------------
# cal_DO_stat requieres barometric pressure in millibars, or a unitted object of barometric pressure.
dat$DO.sat=calc_DO_sat(dat$Temperature,dat$Pressure,model = 'garcia-benson')
dat = dat %>% dplyr::select("solar.time" = solar.time,"DO.obs" = Dissolved_Oxygen,"DO.sat" = DO.sat,"temp.water" = Temperature,"light" = light,"depth" = Depth)
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 2:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
# Chunk 1: setup
#knitr::opts_chunk$set
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # Sets working Directory to the R project
#knitr::opts_chunk$set(eval = FALSE)
#PARENT_ID=params$PARENT_ID
#SITE_ID=params$SITE_ID
# Chunk 2: install
#install.packages(remotes); library(remotes)
# remotes::install_github('appling/unitted', force = TRUE)
# remotes::install_github("USGS-R/streamMetabolizer", force = TRUE)
#install.packages("rstan", dependencies = FALSE)
#install.packages(devtools)
# If you have trouble installing rstan, try the installation codes below:
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan", force = TRUE)
#install.packages("rstan", type = "source")
# Run the line below if you have trouble installing devtools
#devtools::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan")
# Chunk 3: libraries
#rm(list=ls(all=T))
library(fda)
library(streamMetabolizer)
library(dplyr)
library(unitted)
library(ggplot2)
library(tidyr)
library(devtools)
library(rstan)
library(lubridate)
# Correctly installing rstan can be problematic, see GitHub for issues
# Chunk 4: data
#-------------------------------------
#PARENT_ID='' #this is where you would specify a site if you were not running this as a loop
#-------------------------------------
print("PARENT_ID: ")
PARENT_ID<-'SSS001'
print("SITE_ID: ")
SITE_ID<-'S63'
data.path = "Inputs/"
dat = read.csv(paste0(data.path,'Sensor_Files/v2_',PARENT_ID,"_Temp_DO_Press_Depth.csv"),header=T,skip=8)
K600estimates=read.csv(paste0(data.path,'v2_SSS_K600.csv'),header=T,skip=3)
K600estimate<-K600estimates[K600estimates$Site_ID==SITE_ID,2]
print("K600 estimate: ")
K600estimate
#---------------------------------------------------------------------------------------------
file.name = paste('v2_SSS_SM_',PARENT_ID,'_',SITE_ID,'_final',sep='')
#fix erroneous data by removing and replacing with fourrier-smoothed interpolation
dat$timeUTC<-as.POSIXct(dat$DateTime)+hours(8)
dat$timeUTC<-force_tz(dat$timeUTC,tzone='UTC')
tt<- as.integer(format(dat$timeUTC, "%s"))
DO<-dat$Dissolved_Oxygen
#DOWNSAMPLE
samplingmins=15
dat = dat[seq(1, nrow(dat), samplingmins), ]
dat$solar.time<-convert_UTC_to_solartime(dat$timeUTC, longitude= dat$Longitude[1], time.type="mean solar")
dat$light<- calc_light(dat$solar.time, latitude=dat$Latitude[1], longitude=dat$Longitude[1], max.PAR =2300, attach.units = F) #------------------
# cal_DO_stat requieres barometric pressure in millibars, or a unitted object of barometric pressure.
dat$DO.sat=calc_DO_sat(dat$Temperature,dat$Pressure,model = 'garcia-benson')
dat = dat %>% dplyr::select("solar.time" = solar.time,"DO.obs" = Dissolved_Oxygen,"DO.sat" = DO.sat,"temp.water" = Temperature,"light" = light,"depth" = Depth)
bayes_name = mm_name(type='bayes',
pool_K600='normal',
err_obs_iid=TRUE,
err_proc_iid=TRUE)
bayes_name
# Changing the specs
bayes_specs = specs(bayes_name, K600_daily_meanlog_meanlog=log(K600estimate), K600_daily_meanlog_sdlog=0.7, K600_daily_sdlog_sigma=0.02, burnin_steps=1000,
saved_steps=1000)
mm = metab(bayes_specs, data=dat)#
dat = read.csv(paste0(data.path,'Sensor_Files/v2_',PARENT_ID,"_Temp_DO_Press_Depth.csv"),header=T,skip=8)
View(dat)
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
##Matt Kaufman matthew.kaufman@pnnl.gov Pacific Northwest National Laboratory
##This script loads the list of SSS sites from the published metadata and loops through them all,
##running the stream metabolizer template for each one
metadata.path="C:/Users/gara009/OneDrive - PNNL/Documents/GitHub/SSS_metabolism/Published_Data/v2_SSS_Data_Package/" #from this data package: https://data.ess-dive.lbl.gov/datasets/doi:10.15485/1969566
output.path= "Outputs/"
metadata=read.csv(paste(metadata.path,'v2_SSS_Metadata_IGSN-Mapping.csv',sep=''),skip=1,header=T)
metadata <- metadata[grepl("Water", metadata$Sample_Name, ignore.case = TRUE),]
SITE_LIST<-data.frame(substring(metadata$Sample_Name,0,6),metadata$Locality)
colnames(SITE_LIST)<-c('PARENT_ID','SITE_ID')
for(i in 1:length(SITE_LIST[,1])) {
#for(i in 1:1) {
PARENT_ID<-SITE_LIST[i,1]
SITE_ID<-SITE_LIST[i,2]
htmlfilename=paste0(getwd(),"/",output.path,'v2_',PARENT_ID,'_',SITE_ID,'_SM_output.HTML')
rmarkdown::render("Scripts/v2_SSS_SM_final_template.Rmd",
output_file = htmlfilename,
params = list(
PARENT_ID=PARENT_ID,
SITE_ID=SITE_ID
))
}
---
title: "stream metabolizer SSS template"
---
title: "smet_results_analysis"
