list_sub_files
extracted_files
fd = data_in_file[3]
fd
fd =extracted_files[3]
data_in_file<- list()
dir.exists(file.path(new_dir,fd))
# read data in subfolder
subfolder <- file.path(new_dir,fd)
list_sub_files <- list.files(subfolder, pattern = ".csv", recursive = T, full.names = TRUE)
list_sub_files
if (length(list_sub_files)>0){
#list_sub_names <- list.files(subfolder, pattern = ".csv", recursive = T)
lines <- readLines(list_sub_files[1])
sidx<-max(grep("#", lines,ignore.case = TRUE))
DT <- lapply(list_sub_files, function(x) fread(x, skip=sidx, sep=","))
names(DT) <- sub(".*/", "", list_sub_files)
data_in_file[[fd]]<-DT
}
lines
sidx
# read data in subfolder
subfolder <- file.path(new_dir,fd)
list_sub_files <- list.files(subfolder, pattern = ".csv", recursive = T, full.names = TRUE)
list_sub_files
#list_sub_names <- list.files(subfolder, pattern = ".csv", recursive = T)
lines <- readLines(list_sub_files[1])
lines
sidx<-max(grep("#", lines,ignore.case = TRUE))
sidx
grep("#", lines,ignore.case = TRUE)
length(sidx)
grepl("#", lines,ignore.case = TRUE)
any(grepl("#", lines,ignore.case = TRUE))
#list_sub_names <- list.files(subfolder, pattern = ".csv", recursive = T)
lines <- readLines(list_sub_files[1])
if (any(grepl("#", lines,ignore.case = TRUE))){
sidx<-max(grep("#", lines,ignore.case = TRUE))
DT <- lapply(list_sub_files, function(x) fread(x, skip=sidx, sep=","))
}else{
DT <- lapply(list_sub_files, function(x) fread(x, sep=","))
}
View(DT)
names(DT) <- sub(".*/", "", list_sub_files)
data_in_file[[fd]]<-DT
data_in_file$data$Table_1_Butte_2013_2018.csv
data_in_file$data$Table_2_2014_2015.csv
names(data_in_file$data$Table_1_Butte_2013_2018.csv)
list_sub_files
names(data_in_file$data$Table_7_PumphouseQ-DOC-DIC.csv)
data_in_file$data$`Table_7_PumphouseQ-DOC-DIC.csv`
data_in_file$data$Table_1_Butte_2013_2018.csv
dim(data_in_file$data$Table_1_Butte_2013_2018.csv)
colnames(data_in_file$data$Table_1_Butte_2013_2018.csv) <- data_in_file$data$Table_1_Butte_2013_2018.csv[1,]
data_in_file$data$Table_1_Butte_2013_2018.csv[1,]
colnames(data_in_file$data$Table_1_Butte_2013_2018.csv)
dd = data_in_file$data$Table_1_Butte_2013_2018.csv
View(dd)
colnames(data_in_file$data$Table_1_Butte_2013_2018.csv) <- data_in_file$data$Table_1_Butte_2013_2018.csv[2,]
colnames(dd)<- dd[2,]
colnames(dd)
names(dd)<- dd[2,]
dd[2,]
names(dd)
dd%>% row_to_names(row_number = 2)
library(tidyverse)
library(janitor)
dd%>% row_to_names(row_number = 2)
df =dd%>% row_to_names(row_number = 2)
View(df)
data_in_file<- list()
# read the extracted files in folder
for (fd in extracted_files){
# check if subfolder exist
if (dir.exists(file.path(new_dir,fd))){
# read data in subfolder
subfolder <- file.path(new_dir,fd)
list_sub_files <- list.files(subfolder, pattern = ".csv", recursive = T, full.names = TRUE)
if (length(list_sub_files)>0){
#list_sub_names <- list.files(subfolder, pattern = ".csv", recursive = T)
lines <- readLines(list_sub_files[1])
if (any(grepl("#", lines,ignore.case = TRUE))){
sidx<-max(grep("#", lines,ignore.case = TRUE))
DT <- lapply(list_sub_files, function(x) fread(x, skip=sidx, sep=","))
}else{
DT <- lapply(list_sub_files, function(x) fread(x, sep=","))
}
names(DT) <- sub(".*/", "", list_sub_files)
data_in_file[[fd]]<-DT
}
}
else if(grepl('.csv',fd)){
# read .csv files in folder
#dname <- tools::file_path_sans_ext(basename(fd))
fdata<- read.csv(file.path(new_dir, fd))
data_in_file[[fd]]<- fdata
}
}
################################################################################
## function to download file from ESS-DIVE and read file into R
# only file in .csv format will be read into R
download_and_read_data<-function(target_url,filename,downloads_folder,rm_zip=TRUE,rm_unzip_folder=FALSE){
# target_url: the URL of a specific file you want to download from ESS-DIVE
# filename: the filename of the file you want to download from ESS-DIVE
# downloads_folder: target folder to store the downloaded file
# rm_zip: whether to remove the downloaded zip file after unzipped the file, default is TRUE
# rm_unzip_folder: whether to remove the unzip_folder after reading data into R, default is FALSE
destfile <-file.path(downloads_folder,filename)
curl_download(target_url, destfile =destfile)
# Wait for the download to complete
while (length(list.files(path = downloads_folder, pattern = filename)) == 0) {
Sys.sleep(5)
}
# Check if the file is a zip file
is_zip <- tools::file_ext(destfile) == "zip"
#
if (length(list.files(downloads_folder,patt=filename))>0){
if (grepl('.csv',filename)){
data_name <- tools::file_path_sans_ext(basename(destfile))
data_in_file<- read.csv(destfile)
#lines <- readLines(destfile)
#sidx<-max(grep("#", lines,ignore.case = TRUE))
#data_in_file[[data_name]]<- read.csv(destfile,header = TRUE,skip=sidx)
}
else if (is_zip) {
# Extract the file name without the extension
folder_name <- tools::file_path_sans_ext(basename(destfile))
# Create a new directory with the file name
new_dir <- file.path(downloads_folder, folder_name)
if(!dir.exists(new_dir)==T){dir.create(new_dir)}
# Unzip the file into the new directory
unzip(destfile, exdir = new_dir)
# Get the extracted file paths
#extracted_files <- list.files(path = new_dir, full.names = TRUE)
extracted_files <- list.files(path = new_dir)
# Remove the zip file
if(rm_zip==TRUE){
file.remove(destfile)
}
# Print the file names within the folder
cat("Files and folders in", new_dir, "folder:\n")
cat(paste0(extracted_files, "\n"), sep = "")
cat("\n")
data_in_file<- list()
# read the extracted files in folder
for (fd in extracted_files){
# check if subfolder exist
if (dir.exists(file.path(new_dir,fd))){
# read data in subfolder
subfolder <- file.path(new_dir,fd)
list_sub_files <- list.files(subfolder, pattern = ".csv", recursive = T, full.names = TRUE)
if (length(list_sub_files)>0){
#list_sub_names <- list.files(subfolder, pattern = ".csv", recursive = T)
lines <- readLines(list_sub_files[1])
if (any(grepl("#", lines,ignore.case = TRUE))){
sidx<-max(grep("#", lines,ignore.case = TRUE))
DT <- lapply(list_sub_files, function(x) fread(x, skip=sidx, sep=","))
}else{
DT <- lapply(list_sub_files, function(x) fread(x, sep=","))
}
names(DT) <- sub(".*/", "", list_sub_files)
data_in_file[[fd]]<-DT
}
}
else if(grepl('.csv',fd)){
# read .csv files in folder
#dname <- tools::file_path_sans_ext(basename(fd))
fdata<- read.csv(file.path(new_dir, fd))
data_in_file[[fd]]<- fdata
}
}
}
if (rm_unzip_folder==TRUE){
# delete the un_zip directory
unlink(new_dir,recursive=TRUE)
}
return(data_in_file)
}else{
cat("Downloaded file:", filename)
print('No CSV file found !')
}
}
# https://data.ess-dive.lbl.gov/view/doi:10.15485/1969566
filename<-'Dataset.zip'
target_url <-'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/packages/application%2Fbagit-1.0/ess-dive-909866f61f9cfca-20230914T182609104'
data_in_file4 <-download_and_read_data(target_url,filename,downloads_folder)
# https://data.ess-dive.lbl.gov/view/doi:10.15485/1969566
filename<-'Dataset.zip'
target_url <-'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/packages/application%2Fbagit-1.0/ess-dive-909866f61f9cfca-20230914T182609104'
data_in_file4 <-download_and_read_data(target_url,filename,downloads_folder)
View(data_in_file4)
closeAllConnections()
# https://data.ess-dive.lbl.gov/view/doi:10.15485/1969566
filename<-'Dataset.zip'
target_url <-'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/packages/application%2Fbagit-1.0/ess-dive-909866f61f9cfca-20230914T182609104'
data_in_file4 <-download_and_read_data(target_url,filename,downloads_folder)
destfile
# target_url: the URL of a specific file you want to download from ESS-DIVE
# filename: the filename of the file you want to download from ESS-DIVE
# downloads_folder: target folder to store the downloaded file
# rm_zip: whether to remove the downloaded zip file after unzipped the file, default is TRUE
# rm_unzip_folder: whether to remove the unzip_folder after reading data into R, default is FALSE
list.files(downloads_folder)
destfile in existed_files
destfile %in% existed_files
# target_url: the URL of a specific file you want to download from ESS-DIVE
# filename: the filename of the file you want to download from ESS-DIVE
# downloads_folder: target folder to store the downloaded file
# rm_zip: whether to remove the downloaded zip file after unzipped the file, default is TRUE
# rm_unzip_folder: whether to remove the unzip_folder after reading data into R, default is FALSE
existed_files<- list.files(downloads_folder)
destfile <-file.path(downloads_folder,filename)
destfile %in% existed_files
destfile
filename
filename %in% existed_files
!filename %in% existed_files
cat("File:", filename,' already in folder')
cat( filename,' already in folder')
################################################################################
## function to download file from ESS-DIVE and read file into R
# only file in .csv format will be read into R
download_and_read_data<-function(target_url,filename,downloads_folder,rm_zip=TRUE,rm_unzip_folder=FALSE){
# target_url: the URL of a specific file you want to download from ESS-DIVE
# filename: the filename of the file you want to download from ESS-DIVE
# downloads_folder: target folder to store the downloaded file
# rm_zip: whether to remove the downloaded zip file after unzipped the file, default is TRUE
# rm_unzip_folder: whether to remove the unzip_folder after reading data into R, default is FALSE
existed_files<- list.files(downloads_folder)
destfile <-file.path(downloads_folder,filename)
if (!filename %in% existed_files){
curl_download(target_url, destfile =destfile)
}else{
cat( filename,' already in folder')
}
# Wait for the download to complete
while (length(list.files(path = downloads_folder, pattern = filename)) == 0) {
Sys.sleep(5)
}
# Check if the file is a zip file
is_zip <- tools::file_ext(destfile) == "zip"
#
if (length(list.files(downloads_folder,patt=filename))>0){
if (grepl('.csv',filename)){
data_name <- tools::file_path_sans_ext(basename(destfile))
data_in_file<- read.csv(destfile)
#lines <- readLines(destfile)
#sidx<-max(grep("#", lines,ignore.case = TRUE))
#data_in_file[[data_name]]<- read.csv(destfile,header = TRUE,skip=sidx)
}
else if (is_zip) {
# Extract the file name without the extension
folder_name <- tools::file_path_sans_ext(basename(destfile))
# Create a new directory with the file name
new_dir <- file.path(downloads_folder, folder_name)
if(!dir.exists(new_dir)==T){dir.create(new_dir)}
# Unzip the file into the new directory
unzip(destfile, exdir = new_dir)
# Get the extracted file paths
#extracted_files <- list.files(path = new_dir, full.names = TRUE)
extracted_files <- list.files(path = new_dir)
# Remove the zip file
if(rm_zip==TRUE){
file.remove(destfile)
}
# Print the file names within the folder
cat("Files and folders in", new_dir, "folder:\n")
cat(paste0(extracted_files, "\n"), sep = "")
cat("\n")
data_in_file<- list()
# read the extracted files in folder
for (fd in extracted_files){
# check if subfolder exist
if (dir.exists(file.path(new_dir,fd))){
# read data in subfolder
subfolder <- file.path(new_dir,fd)
list_sub_files <- list.files(subfolder, pattern = ".csv", recursive = T, full.names = TRUE)
if (length(list_sub_files)>0){
#list_sub_names <- list.files(subfolder, pattern = ".csv", recursive = T)
lines <- readLines(list_sub_files[1])
if (any(grepl("#", lines,ignore.case = TRUE))){
sidx<-max(grep("#", lines,ignore.case = TRUE))
DT <- lapply(list_sub_files, function(x) fread(x, skip=sidx, sep=","))
}else{
DT <- lapply(list_sub_files, function(x) fread(x, sep=","))
}
names(DT) <- sub(".*/", "", list_sub_files)
data_in_file[[fd]]<-DT
}
}
else if(grepl('.csv',fd)){
# read .csv files in folder
#dname <- tools::file_path_sans_ext(basename(fd))
fdata<- read.csv(file.path(new_dir, fd))
data_in_file[[fd]]<- fdata
}
}
}
if (rm_unzip_folder==TRUE){
# delete the un_zip directory
unlink(new_dir,recursive=TRUE)
}
return(data_in_file)
}else{
cat("Downloaded file:", filename)
print('No CSV file found !')
}
}
# example 4 (the whole package)
# The East River, Colorado, Watershed
# https://data.ess-dive.lbl.gov/view/doi:10.15485/1969566
filename<-'Dataset.zip'
target_url <-'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/packages/application%2Fbagit-1.0/ess-dive-909866f61f9cfca-20230914T182609104'
data_in_file4 <-download_and_read_data(target_url,filename,downloads_folder)
################################################################################
## function to download file from ESS-DIVE and read file into R
# only file in .csv format will be read into R
download_and_read_data<-function(target_url,filename,downloads_folder,rm_zip=TRUE,rm_unzip_folder=FALSE){
# target_url: the URL of a specific file you want to download from ESS-DIVE
# filename: the filename of the file you want to download from ESS-DIVE
# downloads_folder: target folder to store the downloaded file
# rm_zip: whether to remove the downloaded zip file after unzipped the file, default is TRUE
# rm_unzip_folder: whether to remove the unzip_folder after reading data into R, default is FALSE
existed_files<- list.files(downloads_folder)
destfile <-file.path(downloads_folder,filename)
if (!filename %in% existed_files){
curl_download(target_url, destfile =destfile)
}else{
cat( filename,' already in folder')
cat("\n")
}
# Wait for the download to complete
while (length(list.files(path = downloads_folder, pattern = filename)) == 0) {
Sys.sleep(5)
}
# Check if the file is a zip file
is_zip <- tools::file_ext(destfile) == "zip"
#
if (length(list.files(downloads_folder,patt=filename))>0){
if (grepl('.csv',filename)){
data_name <- tools::file_path_sans_ext(basename(destfile))
data_in_file<- read.csv(destfile)
#lines <- readLines(destfile)
#sidx<-max(grep("#", lines,ignore.case = TRUE))
#data_in_file[[data_name]]<- read.csv(destfile,header = TRUE,skip=sidx)
}
else if (is_zip) {
# Extract the file name without the extension
folder_name <- tools::file_path_sans_ext(basename(destfile))
# Create a new directory with the file name
new_dir <- file.path(downloads_folder, folder_name)
if(!dir.exists(new_dir)==T){dir.create(new_dir)}
# Unzip the file into the new directory
unzip(destfile, exdir = new_dir)
# Get the extracted file paths
#extracted_files <- list.files(path = new_dir, full.names = TRUE)
extracted_files <- list.files(path = new_dir)
# Remove the zip file
if(rm_zip==TRUE){
file.remove(destfile)
}
# Print the file names within the folder
cat("Files and folders in", new_dir, "folder:\n")
cat(paste0(extracted_files, "\n"), sep = "")
cat("\n")
data_in_file<- list()
# read the extracted files in folder
for (fd in extracted_files){
# check if subfolder exist
if (dir.exists(file.path(new_dir,fd))){
# read data in subfolder
subfolder <- file.path(new_dir,fd)
list_sub_files <- list.files(subfolder, pattern = ".csv", recursive = T, full.names = TRUE)
if (length(list_sub_files)>0){
#list_sub_names <- list.files(subfolder, pattern = ".csv", recursive = T)
lines <- readLines(list_sub_files[1])
if (any(grepl("#", lines,ignore.case = TRUE))){
sidx<-max(grep("#", lines,ignore.case = TRUE))
DT <- lapply(list_sub_files, function(x) fread(x, skip=sidx, sep=","))
}else{
DT <- lapply(list_sub_files, function(x) fread(x, sep=","))
}
names(DT) <- sub(".*/", "", list_sub_files)
data_in_file[[fd]]<-DT
}
}
else if(grepl('.csv',fd)){
# read .csv files in folder
#dname <- tools::file_path_sans_ext(basename(fd))
fdata<- read.csv(file.path(new_dir, fd))
data_in_file[[fd]]<- fdata
}
}
}
if (rm_unzip_folder==TRUE){
# delete the un_zip directory
unlink(new_dir,recursive=TRUE)
}
return(data_in_file)
}else{
cat("Downloaded file:", filename)
print('No CSV file found !')
}
}
# example 4 (the whole package)
# The East River, Colorado, Watershed
# https://data.ess-dive.lbl.gov/view/doi:10.15485/1969566
filename<-'Dataset.zip'
target_url <-'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/packages/application%2Fbagit-1.0/ess-dive-909866f61f9cfca-20230914T182609104'
data_in_file4 <-download_and_read_data(target_url,filename,downloads_folder)
View(data_in_file4)
# example 5 (the whole package)
# Spatial Study 2022
# https://data.ess-dive.lbl.gov/view/doi:10.15485/1969566
filename<-'SS22.zip'
target_url <-'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/packages/application%2Fbagit-1.0/ess-dive-3e900ef1301125f-20230919T202125785299'
# example 5 (the whole package)
# Spatial Study 2022
# https://data.ess-dive.lbl.gov/view/doi:10.15485/1969566
filename<-'SS22.zip'
target_url <-'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/packages/application%2Fbagit-1.0/ess-dive-3e900ef1301125f-20230919T202125785299'
# target_url: the URL of a specific file you want to download from ESS-DIVE
# filename: the filename of the file you want to download from ESS-DIVE
# downloads_folder: target folder to store the downloaded file
# rm_zip: whether to remove the downloaded zip file after unzipped the file, default is TRUE
# rm_unzip_folder: whether to remove the unzip_folder after reading data into R, default is FALSE
existed_files<- list.files(downloads_folder)
destfile <-file.path(downloads_folder,filename)
destfile
# Extract the file name without the extension
folder_name <- tools::file_path_sans_ext(basename(destfile))
folder_name
# Create a new directory with the file name
new_dir <- file.path(downloads_folder, folder_name)
# Get the extracted file paths
#extracted_files <- list.files(path = new_dir, full.names = TRUE)
extracted_files <- list.files(path = new_dir)
extracted_files
new_dir
# target_url: the URL of a specific file you want to download from ESS-DIVE
# filename: the filename of the file you want to download from ESS-DIVE
# downloads_folder: target folder to store the downloaded file
# rm_zip: whether to remove the downloaded zip file after unzipped the file, default is TRUE
# rm_unzip_folder: whether to remove the unzip_folder after reading data into R, default is FALSE
existed_files<- list.files(downloads_folder)
destfile <-file.path(downloads_folder,filename)
destfile
curl_download(target_url, destfile =destfile)
filename<-'SS22.zip'
target_url <-'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/packages/application%2Fbagit-1.0/ess-dive-3e900ef1301125f-20230919T202125785299'
unzip_recursive <- function(zip_file, extract_path) {
# Get the list of files in the zip archive
files <- unzip(zip_file, exdir = extract_path,list = TRUE)$Name
# Extract each file in the zip archive
walk(files, function(file) {
# Construct the full path of the file in the zip archive
file_in_zip <- file.path(extract_path, file)
# Extract the file to the specified path
unzip(file_in_zip, exdir = extract_path)
})
}
# target_url: the URL of a specific file you want to download from ESS-DIVE
# filename: the filename of the file you want to download from ESS-DIVE
# downloads_folder: target folder to store the downloaded file
# rm_zip: whether to remove the downloaded zip file after unzipped the file, default is TRUE
# rm_unzip_folder: whether to remove the unzip_folder after reading data into R, default is FALSE
existed_files<- list.files(downloads_folder)
destfile <-file.path(downloads_folder,filename)
destfile
# Extract the file name without the extension
folder_name <- tools::file_path_sans_ext(basename(destfile))
# Create a new directory with the file name
new_dir <- file.path(downloads_folder, folder_name)
if(!dir.exists(new_dir)==T){dir.create(new_dir)}
# Unzip the file into the new directory
unzip_recursive(destfile, new_dir) #unzip(destfile, exdir = new_dir)
zip_file
80000*0.2
80000*0.2/60
80000*0.2/60/60
86524-86530
108164
108164-108158
108167-108064
108167-108158
source('./COde/SSS_Sed_Resp_data_merging.R')
setwd("C:/Users/linx882/OneDrive - PNNL/XLin/automation of respiration calculations/SSS_metabolism")
source('./COde/SSS_Sed_Resp_data_merging.R')
outdir<-'./MLR_Analysis_Figures'
##############################################################################################################
# read in data
cdata <- data_merge()
source('./COde/SSS_Sed_Resp_data_merging.R')
outdir<-'./MLR_Analysis_Figures'
##############################################################################################################
# read in data
cdata <- data_merge()
# RC2 spatial study - Multiple linear regression
# ER_sed
# X Lin April 18 2023
################################################################################################
# Read in data
################################################################################################
rm(list=ls(all=TRUE))
source('./COde/SSS_Sed_Resp_data_merging.R')
library(MASS)
library(relaimpo)
library(visreg)
library(ggstatsplot)
library(caret)
library(leaps)
install.packages('lattice')
